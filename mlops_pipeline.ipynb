{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a6f9f34-ae97-435f-8392-c1c68c9a3a36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 필요한 package 들의 kernel 이 시작될 때, 미리 작성해둔 LifeCycle Configurations 의 Script 로 설치될 수 있도록 설정함. \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import IPython\n",
    "\n",
    "#install_needed = True\n",
    "install_needed = False\n",
    "\n",
    "if install_needed:\n",
    "    print(\"===> Installing deps and restarting kernel. Please change 'install_needed = False' and run this code cell again.\")\n",
    "    !{sys.executable} -m pip install -U \"nbformat\" \"argparse\" \"torchvision==0.14.1\"  \"awscli==1.27.68\" \"boto3==1.26.68\" \"botocore==1.29.68\" \"datasets==1.18.4\" \"sagemaker==2.143.0\" \"s3fs==0.4.2\" \"s3transfer==0.6.0\" \"transformers==4.17.0\" \"nvidia-cublas-cu11==11.10.3.66\" \"nvidia-cuda-nvrtc-cu11==11.7.99\" \"nvidia-cuda-runtime-cu11==11.7.99\" \"nvidia-cudnn-cu11==8.5.0.96\"  \n",
    "    IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb05b54",
   "metadata": {
    "id": "0eb05b54"
   },
   "source": [
    "# MLOps with SageMaker Pipelines\n",
    "\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Reference: \n",
    "\n",
    "https://github.com/gonsoomoon-ml/SageMaker-Pipelines-Step-By-Step\n",
    "https://github.com/gonsoomoon-ml/SageMaker-Pipelines-Step-By-Step/tree/main/phase01\n",
    "https://github.com/gonsoomoon-ml/SageMaker-Pipelines-Step-By-Step/tree/main/phase02\n",
    "\n",
    "- SageMaker Pipelines SDK: https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-sdk.html\n",
    "- Caching Pipeline Steps: https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-caching.html\n",
    "- AWS AIML Blog: Use a SageMaker Pipeline Lambda step for lightweight model deployments: https://aws.amazon.com/de/blogs/machine-learning/use-a-sagemaker-pipeline-lambda-step-for-lightweight-model-deployments/\n",
    "\n",
    "[Check]\n",
    "- ROLE :  sagemaker role arn: arn:aws:iam::353411055907:role/service-role/AmazonSageMaker-ExecutionRole-20230315T235247\n",
    "- `AmazonSageMakerFullAccess`와 `AmazonSageMakerPipelinesIntegrations` policy 필수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47e800e8",
   "metadata": {
    "id": "47e800e8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import sagemaker\n",
    "import sagemaker.huggingface\n",
    "from sagemaker.huggingface import HuggingFace, HuggingFaceModel\n",
    "\n",
    "from sagemaker.workflow.parameters import ParameterInteger, ParameterFloat, ParameterString\n",
    "\n",
    "from sagemaker.lambda_helper import Lambda\n",
    "\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.huggingface.processing import HuggingFaceProcessor\n",
    "\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import CacheConfig, ProcessingStep\n",
    "\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "\n",
    "from sagemaker.processing import ScriptProcessor\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.step_collections import CreateModelStep, RegisterModel\n",
    "\n",
    "from sagemaker.workflow.conditions import ConditionLessThanOrEqualTo,ConditionGreaterThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "\n",
    "from sagemaker.workflow.pipeline import Pipeline, PipelineExperimentConfig\n",
    "from sagemaker.workflow.execution_variables import ExecutionVariables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c88b740",
   "metadata": {
    "id": "6c88b740",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::353411055907:role/service-role/AmazonSageMaker-ExecutionRole-20230315T235247\n",
      "sagemaker bucket: sagemaker-us-east-1-353411055907\n",
      "sagemaker session region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "sess = sagemaker.Session()\n",
    "region = sess.boto_region_name\n",
    "\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sagemaker_session = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sagemaker_session.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sagemaker_session.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80082d88-470e-47e9-a153-7e3961296dea",
   "metadata": {
    "tags": []
   },
   "source": [
    "### S3 bucket 에 올려둔 필요한 src , utils 현재 작업 중인 directory 로 가져오기 (for the Scheduling Job by Sagemaker Studio Notebook Jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a37f0be8-e2fb-432f-841d-020e41ac6d01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "# S3 URI 설정\n",
    "s3_uri = 's3://sagemaker-us-east-1-353411055907/GP-LJP-mlops/LJP_MLops.zip'\n",
    "\n",
    "# 현재 작업 중인 디렉토리 경로 가져오기\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# S3에서 파일 다운로드\n",
    "s3 = boto3.client('s3')\n",
    "bucket, key = s3_uri.split('//')[1].split('/', 1)\n",
    "s3.download_file(bucket, key, os.path.join(current_dir, os.path.basename(key)))\n",
    "\n",
    "# 압축 해제\n",
    "zip_file = os.path.join(current_dir, os.path.basename(key))\n",
    "with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "    zip_ref.extractall(current_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf3461c",
   "metadata": {
    "id": "3cf3461c",
    "tags": []
   },
   "source": [
    "\n",
    "## 1. Defining the Pipeline\n",
    "---\n",
    "\n",
    "### 1.1. Pipeline parameters\n",
    "\n",
    "References:  https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-parameters.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1696421d",
   "metadata": {
    "id": "1696421d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# S3 prefix where every assets will be stored\n",
    "s3_prefix = \"GP-LJP-mlops\"\n",
    "\n",
    "# s3 bucket used for storing assets and artifacts\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "# aws region used\n",
    "region = sagemaker_session.boto_region_name\n",
    "\n",
    "# base name prefix for sagemaker jobs (training, processing, inference)\n",
    "base_job_prefix = s3_prefix\n",
    "\n",
    "# Cache configuration for workflow\n",
    "cache_config = CacheConfig(enable_caching=True, expire_after=\"7d\")\n",
    "\n",
    "# package versions\n",
    "transformers_version = '4.17.0'\n",
    "pytorch_version = '1.10.2'\n",
    "py_version = \"py38\"\n",
    "\n",
    "model_id_ = \"lawcompany/KLAID_LJP_base\"\n",
    "tokenizer_id_ = \"lawcompany/KLAID_LJP_base\"\n",
    "dataset_name_ = \"lawcompany/KLAID\"\n",
    "\n",
    "model_id = ParameterString(name=\"ModelId\", default_value=model_id_)\n",
    "tokenizer_id = ParameterString(name=\"TokenizerId\", default_value=tokenizer_id_)\n",
    "dataset_name = ParameterString(name=\"DatasetName\", default_value=dataset_name_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31677317",
   "metadata": {
    "id": "31677317"
   },
   "source": [
    "### 1.2. Processing Step\n",
    "\n",
    "빌트인 `SKLearnProcessor`를 통해 전처리 스텝을 정의\n",
    "\n",
    "References: \n",
    "- AWS AIML Blog: https://aws.amazon.com/ko/blogs/machine-learning/use-deep-learning-frameworks-natively-in-amazon-sagemaker-processing/\n",
    "- 개발자 가이드: https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/build-and-manage-steps.html#step-type-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40481fbc-448a-4773-9a69-a14f2f8c5d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput, ScriptProcessor\n",
    "from sagemaker.workflow.parameters import ParameterString, ParameterInteger\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "import os\n",
    "\n",
    "\n",
    "data_processing_script_py = \"./src/collecting_data.py\"  \n",
    "\n",
    "# S3 버킷 이름과 경로 설정\n",
    "s3_bucket = bucket  # S3 버킷 이름\n",
    "s3_prefix = \"GP-LJP-mlops\"  # S3에 저장할 폴더 이름\n",
    "\n",
    "\n",
    "# 데이터 전처리 스크립트 파일과 출력 경로 설정\n",
    "data_processing_script = \"./src/collecting_data.py\"  # 데이터 전처리를 위한 Python 스크립트 파일\n",
    "output_data_path = f\"s3://{s3_bucket}/{s3_prefix}/data/collected_data\"  # 전처리된 데이터를 저장할 S3 경\n",
    "\n",
    "\n",
    "# file_name 파라미터 정의\n",
    "from datetime import datetime \n",
    "# 현재 날짜와 시간을 문자열로 변환 (예: '2023-08-04 12:00:00')\n",
    "current_date_time_str = datetime.now().strftime('%Y-%m-%d %H')\n",
    "file_name = ParameterString(name='FileName', default_value='data_{current_date_time_str}.csv')\n",
    "\n",
    "# SageMaker SKLearnProcessor 생성\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version='0.23-1',  # 사전 정의된 scikit-learn 버전 지정\n",
    "    role=role,  # 미리 생성한 IAM 역할 ARN을 사용\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    ")\n",
    "\n",
    "\n",
    "# SageMaker Processing Job 정의\n",
    "step_data_collection = ProcessingStep(\n",
    "    name='DataProcessing',\n",
    "    processor=sklearn_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=f\"s3://{s3_bucket}/{s3_prefix}/labels.csv\",\n",
    "            destination=\"/opt/ml/processing/input\",\n",
    "        ),\n",
    "        # 다른 입력 데이터에 대한 설정 추가 (필요에 따라)\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            source=\"/opt/ml/processing/output\",\n",
    "            destination=output_data_path,\n",
    "            output_name='file_name',\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            source=\"/opt/ml/processing/processed_output\",\n",
    "            destination=output_data_path,\n",
    "        )\n",
    "    ],\n",
    "    code=data_processing_script,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae10defb",
   "metadata": {
    "id": "ae10defb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "processing_instance_type = ParameterString(name=\"ProcessingInstanceType\", default_value=\"ml.m5.xlarge\")\n",
    "processing_instance_count = ParameterInteger(name=\"ProcessingInstanceCount\", default_value=1)\n",
    "processing_script = ParameterString(name=\"ProcessingScript\", default_value=\"./src/processing_sklearn.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76708670",
   "metadata": {
    "id": "76708670",
    "tags": []
   },
   "outputs": [],
   "source": [
    "processing_output_destination = f\"s3://{bucket}/{s3_prefix}/data\"\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    instance_type=\"ml.m5.xlarge\", \n",
    "    instance_count=processing_instance_count,\n",
    "    framework_version=\"1.0-1\",    \n",
    "    base_job_name=base_job_prefix + \"-preprocessing\",\n",
    "    sagemaker_session=sagemaker_session,    \n",
    "    role=role\n",
    ")\n",
    "\n",
    "step_process = ProcessingStep(\n",
    "    name=\"ProcessDataForTraining\",\n",
    "    #cache_config=cache_config,\n",
    "    processor=sklearn_processor,\n",
    "    inputs=[\n",
    "        # 여기에 step_data_collection의 file_name을 전달해줍니다.\n",
    "        ProcessingInput(\n",
    "            input_name='file_name',\n",
    "            source=step_data_collection.properties.ProcessingOutputConfig.Outputs['file_name'].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/file_name\",\n",
    "        ),\n",
    "    ],\n",
    "        \n",
    "    job_arguments=[\"--model_id\", model_id_,\n",
    "                   \"--tokenizer_id\", tokenizer_id_,\n",
    "                   \"--dataset_name\", dataset_name_,\n",
    "                   \"--transformers_version\", transformers_version,\n",
    "                   \"--pytorch_version\", pytorch_version,\n",
    "                   #\"--file_name\", file_name  # file_name을 job_arguments로 추가\n",
    "                   \n",
    "                  ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"train\",\n",
    "            destination=f\"{processing_output_destination}/train\",\n",
    "            source=\"/opt/ml/processing/train\",\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"validation\",\n",
    "            destination=f\"{processing_output_destination}/test\",\n",
    "            source=\"/opt/ml/processing/validation\",\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"test\",\n",
    "            destination=f\"{processing_output_destination}/test\",\n",
    "            source=\"/opt/ml/processing/test\",\n",
    "        )        \n",
    "    ],\n",
    "    code=\"./src/processing_sklearn.py\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d497883e-b667-429b-bd27-6876db685bf6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_2023-08-07 12.csv\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "file_name = f\"data_{datetime.datetime.now().strftime('%Y-%m-%d %H')}.csv\"\n",
    "print(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e008ef40",
   "metadata": {
    "id": "e008ef40"
   },
   "source": [
    "### 1.3. Model Training Step\n",
    "\n",
    "이전 랩에서 진행한 훈련 스크립트를 그대로 활용하여 훈련 스텝을 정의합니다. SageMaker Pipelines에 적용하기 위해 워크플로 파라메터(`ParameterInteger, ParameterFloat, ParameterString`)도 같이 정의합니다.\n",
    "\n",
    "훈련, 검증 및 테스트 데이터에 대한 S3 경로는 이전 랩처럼 수동으로 지정하는 것이 아니라 체인으로 연결되는 개념이기에, 아래 예시처럼 전처리 스텝 결괏값(`step_process`)의 프로퍼티(`properties`)를 참조하여 지정해야 합니다.\n",
    "```python\n",
    "\"train\": TrainingInput(\n",
    "    s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34221b76",
   "metadata": {
    "id": "34221b76"
   },
   "source": [
    "#### Training Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7867b16",
   "metadata": {
    "id": "a7867b16",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training step parameters\n",
    "training_entry_point = ParameterString(name=\"TrainingEntryPoint\", default_value=\"train.py\")\n",
    "training_source_dir = ParameterString(name=\"TrainingSourceDir\", default_value=\"./src\")\n",
    "training_instance_type = ParameterString(name=\"TrainingInstanceType\", default_value=\"ml.p3.8xlarge\")\n",
    "training_instance_count = ParameterInteger(name=\"TrainingInstanceCount\", default_value=1)\n",
    "\n",
    "# hyperparameters, which are passed into the training job\n",
    "n_gpus = ParameterString(name=\"NumGPUs\", default_value=\"1\")\n",
    "epochs = ParameterString(name=\"Epochs\", default_value=\"1\")\n",
    "seed = ParameterString(name=\"Seed\", default_value=\"42\")\n",
    "train_batch_size = ParameterString(name=\"TrainBatchSize\", default_value=\"1\")\n",
    "eval_batch_size = ParameterString(name=\"EvalBatchSize\", default_value=\"2\")           \n",
    "learning_rate = ParameterString(name=\"LearningRate\", default_value=\"5e-5\") \n",
    "\n",
    "model_id = ParameterString(name=\"ModelId\", default_value=model_id_)\n",
    "tokenizer_id = ParameterString(name=\"TokenizerId\", default_value=tokenizer_id_)\n",
    "dataset_name = ParameterString(name=\"DatasetName\", default_value=dataset_name_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c19a3c4",
   "metadata": {
    "id": "7c19a3c4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'n_gpus': n_gpus,                       # number of GPUs per instance\n",
    "    'epochs': epochs,                       # number of training epochs\n",
    "    'seed': seed,                           # seed\n",
    "    'train_batch_size': train_batch_size,   # batch size for training\n",
    "    'eval_batch_size': eval_batch_size,     # batch size for evaluation\n",
    "    'warmup_steps': 0,                      # warmup steps\n",
    "    'learning_rate': learning_rate,         # learning rate used during training\n",
    "    'tokenizer_id': model_id,               # pre-trained tokenizer\n",
    "    'model_id': tokenizer_id                # pre-trained model\n",
    "} \n",
    "\n",
    "chkpt_s3_path = f's3://{bucket}/{s3_prefix}/processing/checkpoints'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e654d8cd",
   "metadata": {
    "id": "e654d8cd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point=\"train.py\",\n",
    "    source_dir=\"./src\",\n",
    "    base_job_name=base_job_prefix + \"-training\",\n",
    "    instance_type=\"ml.p3.8xlarge\",\n",
    "    instance_count=training_instance_count,\n",
    "    role=role,\n",
    "    transformers_version=transformers_version,\n",
    "    pytorch_version=pytorch_version,\n",
    "    py_version=py_version,\n",
    "    hyperparameters=hyperparameters,\n",
    "    sagemaker_session=sagemaker_session,    \n",
    "    disable_profiler=True,\n",
    "    debugger_hook_config=False,\n",
    "    checkpoint_s3_uri=chkpt_s3_path,\n",
    "    checkpoint_local_path='/opt/ml/checkpoints'\n",
    ")\n",
    "\n",
    "step_train = TrainingStep(\n",
    "    name=\"TrainModel\",\n",
    "    estimator=huggingface_estimator,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"train\"\n",
    "            ].S3Output.S3Uri\n",
    "        ),\n",
    "        \"test\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"test\"\n",
    "            ].S3Output.S3Uri\n",
    "        ),\n",
    "    },\n",
    "    cache_config=cache_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2609fee",
   "metadata": {
    "id": "d2609fee"
   },
   "source": [
    "### 1.4. Model evaluation Step\n",
    "\n",
    "훈련된 모델의 성능을 평가하기 위해 추가 `ProcessingStep`을 정의합니다. 평가 결과에 따라 모델이 생성, 등록 및 배포되거나 파이프라인이 중단됩니다.\n",
    "평가 결과는 `PropertyFile`에 복사되며, 이는 이후 `ConditionStep`에서 사용됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ab2765",
   "metadata": {
    "id": "90ab2765"
   },
   "source": [
    "#### Evaluation Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "703b47a7",
   "metadata": {
    "id": "703b47a7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluation_script = ParameterString(name=\"EvaluationScript\", default_value=\"./src/evaluate.py\")\n",
    "evaluation_instance_type = ParameterString(name=\"EvaluationInstanceType\", default_value=\"ml.m5.xlarge\")\n",
    "evaluation_instance_count = ParameterInteger(name=\"EvaluationInstanceCount\", default_value=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5d0b36",
   "metadata": {
    "id": "bd5d0b36"
   },
   "source": [
    "#### Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec940dec",
   "metadata": {
    "id": "ec940dec",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msubprocess\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpathlib\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtarfile\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "logger = logging.getLogger()\u001b[37m\u001b[39;49;00m\n",
      "logger.setLevel(logging.INFO)\u001b[37m\u001b[39;49;00m\n",
      "logger.addHandler(logging.StreamHandler())\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "    logger.debug(\u001b[33m\"\u001b[39;49;00m\u001b[33mStarting evaluation.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    model_path = \u001b[33m\"\u001b[39;49;00m\u001b[33m/opt/ml/processing/model/model.tar.gz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mwith\u001b[39;49;00m tarfile.open(model_path) \u001b[34mas\u001b[39;49;00m tar:\u001b[37m\u001b[39;49;00m\n",
      "        tar.extractall(path=\u001b[33m\"\u001b[39;49;00m\u001b[33m./hf_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    logger.debug(os.listdir(\u001b[33m\"\u001b[39;49;00m\u001b[33m./hf_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m./hf_model/evaluation.json\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\u001b[37m\u001b[39;49;00m\n",
      "        eval_result = json.load(f)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    logger.debug(eval_result)\u001b[37m\u001b[39;49;00m\n",
      "    output_dir = \u001b[33m\"\u001b[39;49;00m\u001b[33m/opt/ml/processing/evaluation\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    pathlib.Path(output_dir).mkdir(parents=\u001b[34mTrue\u001b[39;49;00m, exist_ok=\u001b[34mTrue\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    evaluation_path = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00moutput_dir\u001b[33m}\u001b[39;49;00m\u001b[33m/evaluation.json\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(evaluation_path, \u001b[33m\"\u001b[39;49;00m\u001b[33mw\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\u001b[37m\u001b[39;49;00m\n",
      "        f.write(json.dumps(eval_result))\u001b[37m\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "!pygmentize ./src/evaluate.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "874b539e",
   "metadata": {
    "id": "874b539e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "script_eval = SKLearnProcessor(\n",
    "    framework_version=\"1.0-1\",\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    instance_count=evaluation_instance_count,\n",
    "    base_job_name=base_job_prefix + \"-evaluation\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"EvaluationReport\",\n",
    "    output_name=\"evaluation\",\n",
    "    path=\"evaluation.json\",\n",
    ")\n",
    "\n",
    "step_eval = ProcessingStep(\n",
    "    name=\"EvalLoss\",\n",
    "    processor=script_eval,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            destination=\"/opt/ml/processing/model\",\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"evaluation\",\n",
    "            source=\"/opt/ml/processing/evaluation\",\n",
    "            destination=f\"s3://{bucket}/{s3_prefix}/evaluation_report\",\n",
    "        ),\n",
    "    ],\n",
    "    code=\"./src/evaluate.py\",\n",
    "    property_files=[evaluation_report],\n",
    "    cache_config=cache_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6b7f5d",
   "metadata": {
    "id": "da6b7f5d"
   },
   "source": [
    "### 1.5. Register the model\n",
    "\n",
    "훈련된 모델은 모델 패키지 그룹(Model Package Group)의 모델 레지스트리(Model Registry)에 등록됩니다. 모델 레지스트리는 SageMaker Pipelines에서 소개된 개념으로, 기존 SageMaker 모델과 다르게 모델 버전 관리가 가능하며 승인 여부를 지정할 수 있습니다. 모델 승인은 `ConditionStep`의 조건을 만족할 때에만 가능하게 할 수 있습니다. (예: 정확도가 95% 이상인 경우에만 모델 배포)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e860717a",
   "metadata": {
    "id": "e860717a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = HuggingFaceModel(\n",
    "    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    role=role,\n",
    "    transformers_version=transformers_version,\n",
    "    pytorch_version=pytorch_version,\n",
    "    py_version=py_version,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "model_package_group_name = \"LJPModelPackageGroup\"\n",
    "step_register = RegisterModel(\n",
    "    name=\"RegisterModel\",\n",
    "    model=model,\n",
    "    content_types=[\"application/json\"],\n",
    "    response_types=[\"application/json\"],\n",
    "    inference_instances=[\"ml.m5.xlarge\", \"ml.g4dn.xlarge\"],\n",
    "    transform_instances=[\"ml.m5.xlarge\", \"ml.g4dn.xlarge\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status=\"Approved\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219b6810",
   "metadata": {
    "id": "219b6810"
   },
   "source": [
    "### 1.6. Model Deployment\n",
    "\n",
    "\n",
    "`LambdaStep`에서 파생된 커스텀 단계 `ModelDeployment`를 생성합니다. LambdaStep에서 정의한 Lambda 함수를 통해 호스팅 리얼타임 엔드포인트를 배포합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5aec1574",
   "metadata": {
    "id": "5aec1574",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtime\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mboto3\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mworkflow\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mstep_collections\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m StepCollection\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mworkflow\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36m_utils\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m _RegisterModelStep\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mlambda_helper\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Lambda\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mworkflow\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mlambda_step\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m (\u001b[37m\u001b[39;49;00m\n",
      "    LambdaStep,\u001b[37m\u001b[39;49;00m\n",
      "    LambdaOutput,\u001b[37m\u001b[39;49;00m\n",
      "    LambdaOutputTypeEnum,\u001b[37m\u001b[39;49;00m\n",
      ")\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mModelDeployment\u001b[39;49;00m(StepCollection):\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[33m\"\"\"custom step to deploy model as SageMaker Endpoint\"\"\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m(\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        model_name: \u001b[36mstr\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        registered_model: _RegisterModelStep,\u001b[37m\u001b[39;49;00m\n",
      "        endpoint_instance_type,\u001b[37m\u001b[39;49;00m\n",
      "        sagemaker_endpoint_role: \u001b[36mstr\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        autoscaling_policy: \u001b[36mdict\u001b[39;49;00m = \u001b[34mNone\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "    ):\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.name = \u001b[33m\"\u001b[39;49;00m\u001b[33msagemaker-pipelines-model-deployment\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.model_package_arn = registered_model.properties.ModelPackageArn\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.lambda_role = \u001b[36mself\u001b[39;49;00m.create_lambda_role(\u001b[36mself\u001b[39;49;00m.name)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m#        Use the current time to define unique names for the resources created\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        current_time = time.strftime(\u001b[33m\"\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33mm-\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m-\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33mH-\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33mM-\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33mS\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, time.localtime())\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        steps = []\u001b[37m\u001b[39;49;00m\n",
      "        lambda_file = os.path.join(os.path.dirname(os.path.abspath(\u001b[31m__file__\u001b[39;49;00m)), \u001b[33m\"\u001b[39;49;00m\u001b[33mdeploy_handler.py\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# Lambda helper class can be used to create the Lambda function\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.func = Lambda(\u001b[37m\u001b[39;49;00m\n",
      "            function_name=\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[36mself\u001b[39;49;00m.name\u001b[33m}\u001b[39;49;00m\u001b[33m-\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcurrent_time\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "            execution_role_arn=\u001b[36mself\u001b[39;49;00m.lambda_role,\u001b[37m\u001b[39;49;00m\n",
      "            script=lambda_file,\u001b[37m\u001b[39;49;00m\n",
      "            handler=\u001b[33m\"\u001b[39;49;00m\u001b[33mdeploy_handler.lambda_handler\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "            timeout=\u001b[34m600\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "            memory_size=\u001b[34m256\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        )\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# The dictionary retured by the Lambda function is captured by LambdaOutput, each key in the dictionary corresponds to a\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# LambdaOutput\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        output_param_1 = LambdaOutput(output_name=\u001b[33m\"\u001b[39;49;00m\u001b[33mstatusCode\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, output_type=LambdaOutputTypeEnum.String)\u001b[37m\u001b[39;49;00m\n",
      "        output_param_2 = LambdaOutput(output_name=\u001b[33m\"\u001b[39;49;00m\u001b[33mbody\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, output_type=LambdaOutputTypeEnum.String)\u001b[37m\u001b[39;49;00m\n",
      "        output_param_3 = LambdaOutput(output_name=\u001b[33m\"\u001b[39;49;00m\u001b[33mother_key\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, output_type=LambdaOutputTypeEnum.String)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# The inputs provided to the Lambda function can be retrieved via the `event` object within the `lambda_handler` function\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# in the Lambda\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        lambda_step = LambdaStep(\u001b[37m\u001b[39;49;00m\n",
      "            name=\u001b[33m\"\u001b[39;49;00m\u001b[33mModelDeployment\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "            lambda_func=\u001b[36mself\u001b[39;49;00m.func,\u001b[37m\u001b[39;49;00m\n",
      "            inputs={\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mmodel_name\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: model_name + current_time,\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mendpoint_config_name\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: model_name + current_time,\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mendpoint_name\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: model_name,\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mendpoint_instance_type\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: endpoint_instance_type,\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mmodel_package_arn\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[36mself\u001b[39;49;00m.model_package_arn,\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mrole\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: sagemaker_endpoint_role,\u001b[37m\u001b[39;49;00m\n",
      "            },\u001b[37m\u001b[39;49;00m\n",
      "            outputs=[output_param_1, output_param_2, output_param_3],\u001b[37m\u001b[39;49;00m\n",
      "        )\u001b[37m\u001b[39;49;00m\n",
      "        steps.append(lambda_step)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.steps = steps\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mcreate_lambda_role\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, name):\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "\u001b[33m        Create a role for the Lambda function\u001b[39;49;00m\n",
      "\u001b[33m        \"\"\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        role_name = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mname\u001b[33m}\u001b[39;49;00m\u001b[33m-role\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        iam = boto3.client(\u001b[33m\"\u001b[39;49;00m\u001b[33miam\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mtry\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "            response = iam.create_role(\u001b[37m\u001b[39;49;00m\n",
      "                RoleName=role_name,\u001b[37m\u001b[39;49;00m\n",
      "                AssumeRolePolicyDocument=json.dumps(\u001b[37m\u001b[39;49;00m\n",
      "                    {\u001b[37m\u001b[39;49;00m\n",
      "                        \u001b[33m\"\u001b[39;49;00m\u001b[33mVersion\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33m2012-10-17\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "                        \u001b[33m\"\u001b[39;49;00m\u001b[33mStatement\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: [\u001b[37m\u001b[39;49;00m\n",
      "                            {\u001b[37m\u001b[39;49;00m\n",
      "                                \u001b[33m\"\u001b[39;49;00m\u001b[33mEffect\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33mAllow\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "                                \u001b[33m\"\u001b[39;49;00m\u001b[33mPrincipal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: {\u001b[33m\"\u001b[39;49;00m\u001b[33mService\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33mlambda.amazonaws.com\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m},\u001b[37m\u001b[39;49;00m\n",
      "                                \u001b[33m\"\u001b[39;49;00m\u001b[33mAction\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33msts:AssumeRole\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "                            }\u001b[37m\u001b[39;49;00m\n",
      "                        ],\u001b[37m\u001b[39;49;00m\n",
      "                    }\u001b[37m\u001b[39;49;00m\n",
      "                ),\u001b[37m\u001b[39;49;00m\n",
      "                Description=\u001b[33m\"\u001b[39;49;00m\u001b[33mRole for Lambda to call ECS Fargate task\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "            )\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "            role_arn = response[\u001b[33m\"\u001b[39;49;00m\u001b[33mRole\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m][\u001b[33m\"\u001b[39;49;00m\u001b[33mArn\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "            response = iam.attach_role_policy(\u001b[37m\u001b[39;49;00m\n",
      "                RoleName=role_name, PolicyArn=\u001b[33m\"\u001b[39;49;00m\u001b[33marn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "            )\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "            response = iam.attach_role_policy(\u001b[37m\u001b[39;49;00m\n",
      "                PolicyArn=\u001b[33m\"\u001b[39;49;00m\u001b[33marn:aws:iam::aws:policy/AmazonSageMakerFullAccess\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, RoleName=role_name\u001b[37m\u001b[39;49;00m\n",
      "            )\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34mreturn\u001b[39;49;00m role_arn\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mexcept\u001b[39;49;00m iam.exceptions.EntityAlreadyExistsException:\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mUsing ARN from existing role: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mrole_name\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "            response = iam.get_role(RoleName=role_name)\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34mreturn\u001b[39;49;00m response[\u001b[33m\"\u001b[39;49;00m\u001b[33mRole\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m][\u001b[33m\"\u001b[39;49;00m\u001b[33mArn\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "!pygmentize utils/deploy_step.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3f838d5",
   "metadata": {
    "id": "d3f838d5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ARN from existing role: sagemaker-pipelines-model-deployment-role\n"
     ]
    }
   ],
   "source": [
    "# custom Helper Step for ModelDeployment\n",
    "from utils.deploy_step import ModelDeployment\n",
    "\n",
    "# we will use the iam role from the notebook session for the created endpoint\n",
    "# this role will be attached to our endpoint and need permissions, e.g. to download assets from s3\n",
    "sagemaker_endpoint_role=sagemaker.get_execution_role()\n",
    "model_n_ = \"lawcompany/LJP\"\n",
    "model_name = f\"{model_n_.split('/')[-1]}-{time.strftime('%Y-%m-%d-%H-%M-%S', time.localtime())}\"\n",
    "\n",
    "step_deployment = ModelDeployment(\n",
    "    model_name=model_name,\n",
    "    registered_model=step_register.steps[0],\n",
    "    endpoint_instance_type=\"ml.m5.xlarge\",\n",
    "    sagemaker_endpoint_role=sagemaker_endpoint_role,\n",
    "    autoscaling_policy=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2bb0b5",
   "metadata": {
    "id": "ed2bb0b5"
   },
   "source": [
    "### 1.7. Condition for deployment\n",
    "\n",
    "`ConditionStep`을 통해 모델 평가 결과를 검사합니다. 정확도가 일정 이상일 때(accuracy > 0.95) 모델 등록 및 배포 파이프라인을 진행합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0a78f6",
   "metadata": {
    "id": "4a0a78f6"
   },
   "source": [
    "#### Condition Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1052caf6",
   "metadata": {
    "id": "1052caf6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "threshold_accuracy = ParameterFloat(name=\"ThresholdAccuracy\", default_value=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d30042d",
   "metadata": {
    "id": "7d30042d"
   },
   "source": [
    "#### Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4411610",
   "metadata": {
    "id": "a4411610",
    "tags": []
   },
   "outputs": [],
   "source": [
    "cond_gte = ConditionGreaterThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step_name=step_eval.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"eval_accuracy\",\n",
    "    ),\n",
    "    right=threshold_accuracy,\n",
    ")\n",
    "\n",
    "step_cond = ConditionStep(\n",
    "    name=\"CheckEvalAccuracy\",\n",
    "    conditions=[cond_gte],\n",
    "    if_steps=[step_register, step_deployment],\n",
    "    else_steps=[],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a734ad7",
   "metadata": {
    "id": "8a734ad7"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 2. Pipeline definition and execution\n",
    "\n",
    "---\n",
    "\n",
    "모든 스텝을 정의하였다면 파이프라인을 정의합니다. \n",
    "\n",
    "파이프라인 인스턴스는 이름(`name`), 파라메터(`parameters`), 및 스텝(`steps`)으로 구성됩니다. \n",
    "- 파이프라인 이름: (AWS 계정, 리전) 쌍 내에서 고유해야 합니다 \n",
    "- 파라메터: 스텝 정의에 사용했던 모든 파라메터들을 파이프라인에서 정의해야 합니다. \n",
    "- 스텝: 리스트 형태로 이전 스텝들을 정의합니다. 내부적으로 데이터 종속성을 사용하여 각 스텝 간의 관계를 DAG으로 정의하기 때문에 실행 순서대로 나열할 필요는 없습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "443d6b52",
   "metadata": {
    "id": "443d6b52",
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    name=f\"LJP-Pipeline\",\n",
    "    parameters=[\n",
    "        file_name,\n",
    "        model_id,\n",
    "        tokenizer_id,        \n",
    "        dataset_name,\n",
    "        processing_instance_type,\n",
    "        processing_instance_count,\n",
    "        processing_script,\n",
    "        training_entry_point,\n",
    "        training_source_dir,\n",
    "        training_instance_type,\n",
    "        training_instance_count,\n",
    "        evaluation_script,\n",
    "        evaluation_instance_type,\n",
    "        evaluation_instance_count,\n",
    "        threshold_accuracy,\n",
    "        n_gpus,\n",
    "        epochs,\n",
    "        seed,\n",
    "        eval_batch_size,\n",
    "        train_batch_size,\n",
    "        learning_rate,\n",
    "    ],\n",
    "    steps=[step_data_collection, step_process, step_train, step_eval, step_cond],\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65baea5",
   "metadata": {
    "id": "c65baea5"
   },
   "source": [
    "#### Check the pipeline definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ce7e899",
   "metadata": {
    "id": "4ce7e899",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Version': '2020-12-01',\n",
       " 'Metadata': {},\n",
       " 'Parameters': [{'Name': 'ModelId',\n",
       "   'Type': 'String',\n",
       "   'DefaultValue': 'lawcompany/KLAID_LJP_base'},\n",
       "  {'Name': 'TokenizerId',\n",
       "   'Type': 'String',\n",
       "   'DefaultValue': 'lawcompany/KLAID_LJP_base'},\n",
       "  {'Name': 'DatasetName',\n",
       "   'Type': 'String',\n",
       "   'DefaultValue': 'lawcompany/KLAID'},\n",
       "  {'Name': 'ProcessingInstanceType',\n",
       "   'Type': 'String',\n",
       "   'DefaultValue': 'ml.m5.xlarge'},\n",
       "  {'Name': 'ProcessingInstanceCount', 'Type': 'Integer', 'DefaultValue': 1},\n",
       "  {'Name': 'ProcessingScript',\n",
       "   'Type': 'String',\n",
       "   'DefaultValue': './src/processing_sklearn.py'},\n",
       "  {'Name': 'TrainingEntryPoint', 'Type': 'String', 'DefaultValue': 'train.py'},\n",
       "  {'Name': 'TrainingSourceDir', 'Type': 'String', 'DefaultValue': './src'},\n",
       "  {'Name': 'TrainingInstanceType',\n",
       "   'Type': 'String',\n",
       "   'DefaultValue': 'ml.p3.8xlarge'},\n",
       "  {'Name': 'TrainingInstanceCount', 'Type': 'Integer', 'DefaultValue': 1},\n",
       "  {'Name': 'EvaluationScript',\n",
       "   'Type': 'String',\n",
       "   'DefaultValue': './src/evaluate.py'},\n",
       "  {'Name': 'EvaluationInstanceType',\n",
       "   'Type': 'String',\n",
       "   'DefaultValue': 'ml.m5.xlarge'},\n",
       "  {'Name': 'EvaluationInstanceCount', 'Type': 'Integer', 'DefaultValue': 1},\n",
       "  {'Name': 'ThresholdAccuracy', 'Type': 'Float', 'DefaultValue': 0.95},\n",
       "  {'Name': 'NumGPUs', 'Type': 'String', 'DefaultValue': '1'},\n",
       "  {'Name': 'Epochs', 'Type': 'String', 'DefaultValue': '1'},\n",
       "  {'Name': 'Seed', 'Type': 'String', 'DefaultValue': '42'},\n",
       "  {'Name': 'EvalBatchSize', 'Type': 'String', 'DefaultValue': '2'},\n",
       "  {'Name': 'TrainBatchSize', 'Type': 'String', 'DefaultValue': '1'},\n",
       "  {'Name': 'LearningRate', 'Type': 'String', 'DefaultValue': '5e-5'}],\n",
       " 'PipelineExperimentConfig': {'ExperimentName': {'Get': 'Execution.PipelineName'},\n",
       "  'TrialName': {'Get': 'Execution.PipelineExecutionId'}},\n",
       " 'Steps': [{'Name': 'DataProcessing',\n",
       "   'Type': 'Processing',\n",
       "   'Arguments': {'ProcessingResources': {'ClusterConfig': {'InstanceType': 'ml.m5.xlarge',\n",
       "      'InstanceCount': 1,\n",
       "      'VolumeSizeInGB': 30}},\n",
       "    'AppSpecification': {'ImageUri': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:0.23-1-cpu-py3',\n",
       "     'ContainerEntrypoint': ['python3',\n",
       "      '/opt/ml/processing/input/code/collecting_data.py']},\n",
       "    'RoleArn': 'arn:aws:iam::353411055907:role/service-role/AmazonSageMaker-ExecutionRole-20230315T235247',\n",
       "    'ProcessingInputs': [{'InputName': 'input-1',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-353411055907/GP-LJP-mlops/labels.csv',\n",
       "       'LocalPath': '/opt/ml/processing/input',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}},\n",
       "     {'InputName': 'code',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-353411055907/DataProcessing-b83cdd6b06322985c2c4ed3de7ccf05b/input/code/collecting_data.py',\n",
       "       'LocalPath': '/opt/ml/processing/input/code',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}}],\n",
       "    'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'file_name',\n",
       "       'AppManaged': False,\n",
       "       'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-353411055907/GP-LJP-mlops/data/collected_data',\n",
       "        'LocalPath': '/opt/ml/processing/output',\n",
       "        'S3UploadMode': 'EndOfJob'}},\n",
       "      {'OutputName': 'output-2',\n",
       "       'AppManaged': False,\n",
       "       'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-353411055907/GP-LJP-mlops/data/collected_data',\n",
       "        'LocalPath': '/opt/ml/processing/processed_output',\n",
       "        'S3UploadMode': 'EndOfJob'}}]}}},\n",
       "  {'Name': 'ProcessDataForTraining',\n",
       "   'Type': 'Processing',\n",
       "   'Arguments': {'ProcessingResources': {'ClusterConfig': {'InstanceType': 'ml.m5.xlarge',\n",
       "      'InstanceCount': {'Get': 'Parameters.ProcessingInstanceCount'},\n",
       "      'VolumeSizeInGB': 30}},\n",
       "    'AppSpecification': {'ImageUri': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:1.0-1-cpu-py3',\n",
       "     'ContainerArguments': ['--model_id',\n",
       "      'lawcompany/KLAID_LJP_base',\n",
       "      '--tokenizer_id',\n",
       "      'lawcompany/KLAID_LJP_base',\n",
       "      '--dataset_name',\n",
       "      'lawcompany/KLAID',\n",
       "      '--transformers_version',\n",
       "      '4.17.0',\n",
       "      '--pytorch_version',\n",
       "      '1.10.2'],\n",
       "     'ContainerEntrypoint': ['python3',\n",
       "      '/opt/ml/processing/input/code/processing_sklearn.py']},\n",
       "    'RoleArn': 'arn:aws:iam::353411055907:role/service-role/AmazonSageMaker-ExecutionRole-20230315T235247',\n",
       "    'ProcessingInputs': [{'InputName': 'file_name',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': {'Get': \"Steps.DataProcessing.ProcessingOutputConfig.Outputs['file_name'].S3Output.S3Uri\"},\n",
       "       'LocalPath': '/opt/ml/processing/file_name',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}},\n",
       "     {'InputName': 'code',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-353411055907/ProcessDataForTraining-6f0414932b7dbd80a1ea51072c2f973b/input/code/processing_sklearn.py',\n",
       "       'LocalPath': '/opt/ml/processing/input/code',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}}],\n",
       "    'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'train',\n",
       "       'AppManaged': False,\n",
       "       'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-353411055907/GP-LJP-mlops/data/train',\n",
       "        'LocalPath': '/opt/ml/processing/train',\n",
       "        'S3UploadMode': 'EndOfJob'}},\n",
       "      {'OutputName': 'validation',\n",
       "       'AppManaged': False,\n",
       "       'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-353411055907/GP-LJP-mlops/data/test',\n",
       "        'LocalPath': '/opt/ml/processing/validation',\n",
       "        'S3UploadMode': 'EndOfJob'}},\n",
       "      {'OutputName': 'test',\n",
       "       'AppManaged': False,\n",
       "       'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-353411055907/GP-LJP-mlops/data/test',\n",
       "        'LocalPath': '/opt/ml/processing/test',\n",
       "        'S3UploadMode': 'EndOfJob'}}]}}},\n",
       "  {'Name': 'TrainModel',\n",
       "   'Type': 'Training',\n",
       "   'Arguments': {'AlgorithmSpecification': {'TrainingInputMode': 'File',\n",
       "     'TrainingImage': '763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-training:1.10.2-transformers4.17.0-gpu-py38-cu113-ubuntu20.04',\n",
       "     'EnableSageMakerMetricsTimeSeries': True},\n",
       "    'OutputDataConfig': {'S3OutputPath': 's3://sagemaker-us-east-1-353411055907/'},\n",
       "    'StoppingCondition': {'MaxRuntimeInSeconds': 86400},\n",
       "    'ResourceConfig': {'VolumeSizeInGB': 30,\n",
       "     'InstanceCount': {'Get': 'Parameters.TrainingInstanceCount'},\n",
       "     'InstanceType': 'ml.p3.8xlarge'},\n",
       "    'RoleArn': 'arn:aws:iam::353411055907:role/service-role/AmazonSageMaker-ExecutionRole-20230315T235247',\n",
       "    'InputDataConfig': [{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "        'S3Uri': {'Get': \"Steps.ProcessDataForTraining.ProcessingOutputConfig.Outputs['train'].S3Output.S3Uri\"},\n",
       "        'S3DataDistributionType': 'FullyReplicated'}},\n",
       "      'ChannelName': 'train'},\n",
       "     {'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "        'S3Uri': {'Get': \"Steps.ProcessDataForTraining.ProcessingOutputConfig.Outputs['test'].S3Output.S3Uri\"},\n",
       "        'S3DataDistributionType': 'FullyReplicated'}},\n",
       "      'ChannelName': 'test'}],\n",
       "    'HyperParameters': {'n_gpus': {'Get': 'Parameters.NumGPUs'},\n",
       "     'epochs': {'Get': 'Parameters.Epochs'},\n",
       "     'seed': {'Get': 'Parameters.Seed'},\n",
       "     'train_batch_size': {'Get': 'Parameters.TrainBatchSize'},\n",
       "     'eval_batch_size': {'Get': 'Parameters.EvalBatchSize'},\n",
       "     'warmup_steps': '0',\n",
       "     'learning_rate': {'Get': 'Parameters.LearningRate'},\n",
       "     'tokenizer_id': {'Get': 'Parameters.ModelId'},\n",
       "     'model_id': {'Get': 'Parameters.TokenizerId'},\n",
       "     'sagemaker_submit_directory': '\"s3://sagemaker-us-east-1-353411055907/TrainModel-848396b9281a27f9e148c0de85556d81/source/sourcedir.tar.gz\"',\n",
       "     'sagemaker_program': '\"train.py\"',\n",
       "     'sagemaker_container_log_level': '20',\n",
       "     'sagemaker_region': '\"us-east-1\"'},\n",
       "    'CheckpointConfig': {'S3Uri': 's3://sagemaker-us-east-1-353411055907/GP-LJP-mlops/processing/checkpoints',\n",
       "     'LocalPath': '/opt/ml/checkpoints'},\n",
       "    'ProfilerConfig': {'DisableProfiler': True}},\n",
       "   'CacheConfig': {'Enabled': True, 'ExpireAfter': '7d'}},\n",
       "  {'Name': 'EvalLoss',\n",
       "   'Type': 'Processing',\n",
       "   'Arguments': {'ProcessingResources': {'ClusterConfig': {'InstanceType': 'ml.m5.xlarge',\n",
       "      'InstanceCount': {'Get': 'Parameters.EvaluationInstanceCount'},\n",
       "      'VolumeSizeInGB': 30}},\n",
       "    'AppSpecification': {'ImageUri': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:1.0-1-cpu-py3',\n",
       "     'ContainerEntrypoint': ['python3',\n",
       "      '/opt/ml/processing/input/code/evaluate.py']},\n",
       "    'RoleArn': 'arn:aws:iam::353411055907:role/service-role/AmazonSageMaker-ExecutionRole-20230315T235247',\n",
       "    'ProcessingInputs': [{'InputName': 'input-1',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': {'Get': 'Steps.TrainModel.ModelArtifacts.S3ModelArtifacts'},\n",
       "       'LocalPath': '/opt/ml/processing/model',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}},\n",
       "     {'InputName': 'code',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-353411055907/EvalLoss-fe4cbb9e83a85e0c1bca3690214ab835/input/code/evaluate.py',\n",
       "       'LocalPath': '/opt/ml/processing/input/code',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}}],\n",
       "    'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'evaluation',\n",
       "       'AppManaged': False,\n",
       "       'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-353411055907/GP-LJP-mlops/evaluation_report',\n",
       "        'LocalPath': '/opt/ml/processing/evaluation',\n",
       "        'S3UploadMode': 'EndOfJob'}}]}},\n",
       "   'CacheConfig': {'Enabled': True, 'ExpireAfter': '7d'},\n",
       "   'PropertyFiles': [{'PropertyFileName': 'EvaluationReport',\n",
       "     'OutputName': 'evaluation',\n",
       "     'FilePath': 'evaluation.json'}]},\n",
       "  {'Name': 'CheckEvalAccuracy',\n",
       "   'Type': 'Condition',\n",
       "   'Arguments': {'Conditions': [{'Type': 'GreaterThanOrEqualTo',\n",
       "      'LeftValue': {'Std:JsonGet': {'PropertyFile': {'Get': 'Steps.EvalLoss.PropertyFiles.EvaluationReport'},\n",
       "        'Path': 'eval_accuracy'}},\n",
       "      'RightValue': {'Get': 'Parameters.ThresholdAccuracy'}}],\n",
       "    'IfSteps': [{'Name': 'RegisterModel-RegisterModel',\n",
       "      'Type': 'RegisterModel',\n",
       "      'Arguments': {'ModelPackageGroupName': 'LJPModelPackageGroup',\n",
       "       'InferenceSpecification': {'Containers': [{'Image': '763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-inference:1.10.2-transformers4.17.0-cpu-py38-ubuntu20.04',\n",
       "          'Environment': {'SAGEMAKER_PROGRAM': '',\n",
       "           'SAGEMAKER_SUBMIT_DIRECTORY': '',\n",
       "           'SAGEMAKER_CONTAINER_LOG_LEVEL': '20',\n",
       "           'SAGEMAKER_REGION': 'us-east-1'},\n",
       "          'ModelDataUrl': {'Get': 'Steps.TrainModel.ModelArtifacts.S3ModelArtifacts'}}],\n",
       "        'SupportedContentTypes': ['application/json'],\n",
       "        'SupportedResponseMIMETypes': ['application/json'],\n",
       "        'SupportedRealtimeInferenceInstanceTypes': ['ml.m5.xlarge',\n",
       "         'ml.g4dn.xlarge'],\n",
       "        'SupportedTransformInstanceTypes': ['ml.m5.xlarge', 'ml.g4dn.xlarge']},\n",
       "       'ModelApprovalStatus': 'Approved'}},\n",
       "     {'Name': 'ModelDeployment',\n",
       "      'Type': 'Lambda',\n",
       "      'Arguments': {'model_name': 'LJP-2023-08-07-12-59-1408-07-12-59-14',\n",
       "       'endpoint_config_name': 'LJP-2023-08-07-12-59-1408-07-12-59-14',\n",
       "       'endpoint_name': 'LJP-2023-08-07-12-59-14',\n",
       "       'endpoint_instance_type': 'ml.m5.xlarge',\n",
       "       'model_package_arn': {'Get': 'Steps.RegisterModel-RegisterModel.ModelPackageArn'},\n",
       "       'role': 'arn:aws:iam::353411055907:role/service-role/AmazonSageMaker-ExecutionRole-20230315T235247'},\n",
       "      'FunctionArn': 'arn:aws:lambda:us-east-1:353411055907:function:sagemaker-pipelines-model-deployment-08-07-12-59-14',\n",
       "      'OutputParameters': [{'OutputName': 'statusCode',\n",
       "        'OutputType': 'String'},\n",
       "       {'OutputName': 'body', 'OutputType': 'String'},\n",
       "       {'OutputName': 'other_key', 'OutputType': 'String'}]}],\n",
       "    'ElseSteps': []}}]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "definition = json.loads(pipeline.definition())\n",
    "definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b928bbcb",
   "metadata": {
    "id": "b928bbcb",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n",
      "Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:353411055907:pipeline/ljp-pipeline',\n",
       " 'ResponseMetadata': {'RequestId': '785a4a05-4d39-4fac-b8e9-ec7e749bb769',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '785a4a05-4d39-4fac-b8e9-ec7e749bb769',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '80',\n",
       "   'date': 'Mon, 07 Aug 2023 12:59:19 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7c3357",
   "metadata": {
    "id": "3c7c3357"
   },
   "source": [
    "### Run the pipeline\n",
    "\n",
    "파이프라인을 실행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2265a690",
   "metadata": {
    "id": "2265a690",
    "tags": []
   },
   "outputs": [],
   "source": [
    "execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86a497cc",
   "metadata": {
    "id": "86a497cc",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:353411055907:pipeline/ljp-pipeline',\n",
       " 'PipelineExecutionArn': 'arn:aws:sagemaker:us-east-1:353411055907:pipeline/ljp-pipeline/execution/anu8oatvmh7v',\n",
       " 'PipelineExecutionDisplayName': 'execution-1691413160174',\n",
       " 'PipelineExecutionStatus': 'Executing',\n",
       " 'CreationTime': datetime.datetime(2023, 8, 7, 12, 59, 20, 68000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2023, 8, 7, 12, 59, 20, 68000, tzinfo=tzlocal()),\n",
       " 'CreatedBy': {'UserProfileArn': 'arn:aws:sagemaker:us-east-1:353411055907:user-profile/d-irdpcbrlhtyb/default-1680148488767',\n",
       "  'UserProfileName': 'default-1680148488767',\n",
       "  'DomainId': 'd-irdpcbrlhtyb'},\n",
       " 'LastModifiedBy': {'UserProfileArn': 'arn:aws:sagemaker:us-east-1:353411055907:user-profile/d-irdpcbrlhtyb/default-1680148488767',\n",
       "  'UserProfileName': 'default-1680148488767',\n",
       "  'DomainId': 'd-irdpcbrlhtyb'},\n",
       " 'ResponseMetadata': {'RequestId': 'b6b44c9d-8310-4057-a941-b1b7d13b6264',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'b6b44c9d-8310-4057-a941-b1b7d13b6264',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '747',\n",
       "   'date': 'Mon, 07 Aug 2023 12:59:19 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "815c45d8",
   "metadata": {
    "id": "815c45d8",
    "tags": []
   },
   "outputs": [
    {
     "ename": "WaiterError",
     "evalue": "Waiter PipelineExecutionComplete failed: Waiter encountered a terminal failure state: For expression \"PipelineExecutionStatus\" we matched expected path: \"Failed\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWaiterError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-72be0c8b7085>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexecution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sagemaker/workflow/pipeline.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, delay, max_attempts)\u001b[0m\n\u001b[1;32m    615\u001b[0m             \u001b[0mwaiter_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m         )\n\u001b[0;32m--> 617\u001b[0;31m         \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPipelineExecutionArn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/botocore/waiter.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m# method.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mWaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     wait.__doc__ = WaiterDocstring(\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/botocore/waiter.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0macceptor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplanation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m                 )\n\u001b[0;32m--> 375\u001b[0;31m                 raise WaiterError(\n\u001b[0m\u001b[1;32m    376\u001b[0m                     \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m                     \u001b[0mreason\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWaiterError\u001b[0m: Waiter PipelineExecutionComplete failed: Waiter encountered a terminal failure state: For expression \"PipelineExecutionStatus\" we matched expected path: \"Failed\""
     ]
    }
   ],
   "source": [
    "execution.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d1db77",
   "metadata": {
    "id": "61d1db77"
   },
   "source": [
    "실행된 스텝들을 리스트업합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421ab6aa",
   "metadata": {
    "id": "421ab6aa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "execution.list_steps()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d8821d",
   "metadata": {
    "id": "46d8821d"
   },
   "source": [
    "<br>\n",
    "\n",
    "## Clean up\n",
    "---\n",
    "\n",
    "과금을 방지하기 위해 사용하지 않는 리소스를 삭제합니다. 아래 코드셀은 Lambda 함수와 엔드포인트를 삭제합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491afc1c",
   "metadata": {
    "id": "491afc1c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "sm_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "# Delete the Lambda function\n",
    "step_deployment.func.delete()\n",
    "\n",
    "# Endpoint 는 그냥 추후에 미사용시 삭제 \n",
    "# Delete the endpoint\n",
    "#hf_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a61362-4369-4226-9268-0515ae18a766",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.13 Python 3.9 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.13-cpu-py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "lcc_arn": "arn:aws:sagemaker:us-east-1:353411055907:studio-lifecycle-config/install-pip-package-on-kernel"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
